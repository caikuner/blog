---
title: 计算机网络总结
date: 2021-07-12 14:20:36
permalink: /pages/19e1a2/
categories:
  - 计算机网络
tags:
  - 计算机网络
---
![](https://cdn.nlark.com/yuque/0/2021/png/523629/1619405358858-06f63945-ee51-4665-94e5-9db96c9a27b5.png#align=left&display=inline&height=247&id=wiabB&margin=%5Bobject%20Object%5D&originHeight=249&originWidth=604&size=0&status=done&style=none&width=600)
        网络技术是前端页面数据交互的桥梁，在前端岗的校招中，除了前端方面的知识以外，计算机基础里面最重要的就是**计算机网络**。可以结合相关书籍进行全面学习。其中较为常考的主要有：

- OSI 七层模型、TCP/IP 协议栈 各层中的传输协议
- TCP/UDP 区别、TCP 三次握手四次挥手、滑动窗口
- HTTP/HTTPS 区别、HTTP 各版本、HTTP 报文结构等等。



这类知识比较枯燥繁琐，在学的时候可以通过画图来加强记忆。
        

- 浏览器的网络安全攻防问题千万不可忽视，常见的攻击如 CSRF、XSS、SQL 注入的攻击原理与途径，应对的防御措施都需要熟悉与理解，多看一些常见攻击案例，如经典的 CSRF 银行案例，不仅有助于理解，在面试时也能通过举例阐述得更加清楚。

---

## 1 OSI七层模型 和 TCP/IP四层概念层模型
 OSI体系结构，意为[开放式系统互联](https://baike.baidu.com/item/%E5%BC%80%E6%94%BE%E5%BC%8F%E7%B3%BB%E7%BB%9F%E4%BA%92%E8%81%94/562749)

| OSI七层模型(不用) | TCP/IP四层概念层模型 | 功能 | TCP/IP协议族 | 设备 |
| --- | --- | --- | --- | --- |
| 应用层

允许访问 OSI 环境的手段 | 应用层

**应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则**。对于不同的网络应用需要不同的应用层协议。 | 文件传输，电子邮件，文件服务，虚拟终端等 | 简单文件传输协议TFTP
[简单网络管理协议](https://baike.baidu.com/item/%E7%AE%80%E5%8D%95%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%8D%8F%E8%AE%AE/2986113)SNMP
[简单邮件传输协议](https://baike.baidu.com/item/%E7%AE%80%E5%8D%95%E9%82%AE%E4%BB%B6%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE/10185403)SMTP
[超文本传输协议HTTP](https://baike.baidu.com/item/%E8%B6%85%E6%96%87%E6%9C%AC%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AEHTTP/22265795)
[文件传输协议](https://baike.baidu.com/item/%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE/1874113)FTP
域名系统DNS
远程登录协议Telnet
等 |  |
| 表示层

对数据进行翻译、加密和压缩 |  | 数据转换，数据加密 | 无 |  |
| 会话层

建立、管理和终止会话 |  | 维护网络中的连接状态 | 无 |  |
| 传输层 | 传输层 | （在互连网中源[主机](https://baike.baidu.com/item/%E4%B8%BB%E6%9C%BA)与目的主机的对等实体间）提供端对端的接口 | [传输控制协议TCP](https://baike.baidu.com/item/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AETCP/22264413)（是一种可靠的面向[连接协议](https://baike.baidu.com/item/%E8%BF%9E%E6%8E%A5%E5%8D%8F%E8%AE%AE)）

[用户数据报协议](https://baike.baidu.com/item/%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%8D%8F%E8%AE%AE)UDP（是一种不可靠的[无连接协议](https://baike.baidu.com/item/%E6%97%A0%E8%BF%9E%E6%8E%A5%E5%8D%8F%E8%AE%AE)） | 网关 |
| 网络层 | 网络层 | 为数据包选择路由,确保计算机通信的数据及时传送 | 网际互连协议IP
Internet控制[报文](https://baike.baidu.com/item/%E6%8A%A5%E6%96%87/3164352)协议ICMP
路由信息协议RIP
组播扩展[OSPF](https://baike.baidu.com/item/OSPF%E8%B7%AF%E7%94%B1%E5%8D%8F%E8%AE%AE/10984752)
边界网关协议BGP
Internet组管理协议IGMP | 路由器、三层交换机、网关 |
| **数据链路层** | **链路层** | 传输有地址的帧以及错误检测功能 | 串行线路网际协议SLIP
压缩串行线路网际协议cSLIP
点对点协议PPP
地址解析协议ARP
反向地址转换协议RARP
 | 网桥、二层交换机、网卡 |
| 物理层 |  | 以二进制数据形式在物理媒体上传输数据 |  | 集线器、中继器、网卡、电缆连线连接器 |

### 
### 问：说一说OSI七层模型/如何理解OSI七层模型


OSI 开放式系统互联模型是一个开放性的通行系统互连参考模型，是一个协议规范。它把网络协议从逻辑上分了七层，是一种框架性的设计方法，设计的主要目的是为了解决异种网络互联时遇到的兼容问题，主要功能就是帮助不同类型的主机实现数据传输。最大优点是将服务，协议，接口三者明确的区分开来，通过七个层次化的结构模型使得不同的主机不同的网络之间实现可靠的通讯。服务说明下一层为上一层提供什么功能，接口说明上一层如何实现下一层提供的服务，协议涉及本层如何实现自己的服务。下面我具体说一下每一层：

- 第一层为物理层
   - 物理层的任务就是为它的上一层提供一个物理连接，以及它们的机械、电气、功能和过程特性。如规定使用电缆和接头的类型、传送信号的电压等。在这一层，数据还没有被组织，仅作为原始的位流或电气电压处理，单位是比特。
- 第二层为数据链路层
   - 控制物理层和网络层之间的通讯，把网络层的数据分割成物理层可以传输的帧。
- 第三层为网络层
   -  将网络地址翻译成对应的物理地址，并决定如何将数据从发送方路由到接收方。通过综合考虑发送优先权、网络拥塞程度、服务质量以及可选路由的花费来决定从一个网络中节点Ａ 到另一个网络中节点Ｂ 的最佳路径。
- 第四层为传输层
   - 最重要的一层。可以对传输进行流量控制或是基于接收方的接受速度规定发送速率。如果数据包过大，可以将数据包分解，编序列号，到达接收端后，由于使用相同协议，可以按照编号重组，此过程称为排序。
- 第五层为会话层
   -  负责网络中两个节点之间建立和保持通信，会话层的功能包括：建立通信链接，保持会话过程通信链接的畅通，同步两个节点之间的对 话，决定通信是否被中断以及通信中断时决定从何处重新发送。
- 第六层为表示层
   - 应用程序和网络之间的翻译官，在表示层，数据将按照网络能理解的方案进行格式化；这种格式化也因所使用网络的类型不同而不同。表示层管理数据的解密与加密，如系统口令的处理。在网络中传输需要加密数据的时候，表示层进行加密解密。对图片的编码解码也是表示层的工作。



### 问：说一说TCP/IP协议栈


tcp/ip网络模型分为四层，上之下分别是 应用层，传输层，网络层，链路层。

- 首先说应用层。

       在应用层上的协议都是为了解决某一类应用问题。在这个层次上的协议有http（80端口）,telnet（23端口）,ftp（21端口）,tftp（69端口）,dns（53端口）等协议。这些都对应于我们电脑上的服务，而每个服务都对应与一个端口，用于进程间的通信。

- 然后说传输层。

       传输层指的就是我们常说的tcp 和udp协议了。它们是用来传输数据的。应用层上的协议都是基于tcp或者udp协议进行传输的，比如说http和ftp都是基于tcp协议进行传输的，而dns和ftp是基于udp进行传输的。tcp是面向连接的，传输数据是可靠的。而udp是不可靠的，但它速度快，适用于不怕数据丢失的场景。

- 接着说网络层。

        这里主要就是ip协议，ARP协议，和icmp协议。我理解的ip协议是一个ip地址系统和ip报文，用于互联网上的数据报文传输。而ARP协议是解决同一个局域网上的主机或路由器的ip地址和硬件地址的映射问题的，每一个主机都设有一个高速的ARP高速缓存，里面有此局域网上的各主机和路由器的ip地址到硬件地址的映射表。这样就辅助了一波ip协议。然后就是icmp协议，icmp报文作为ip层数据报的数据，加上数据报的首部，组成ip数据报发送出去。它的重要应用有ping命令，就是常用来检测是否可以和某主机进行通信的一个dos命令。当你ping一台主机时，就是在给该主机一次性发送4个icmp回送请求报文（就是如果对面主机收到则肯定会给你回应）。还有tracert命令，就是用来查看到达目的主机所经过的路由信息的命令。这里发送的是udp数据报，就是发送从小到大的ttl值到经过的路由器，然后生命值结束即返回。

- 最后说一下链路层，

         也就是七层网络模型中的数据链路层和物理层。这就是最底层的东西了。里面有ppp等协议。


## 2. 应用层 HTTP、Websocket、RPC、DNS


### 问：HTTP 是什么、特性
HTTP 是超文本传输协议，也就是HyperText Transfer Protocol。HTTP 是一个用在计算机世界里的协议。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范(两个以上的参与者)，以及相关的各种控制和错误处理方式(行为约定和规范)。HTTP 是一个在计算机世界里专门用来在两点之间传输数据的约定和规范。再来理解「超文本」，它就是超越了普通文本的文本，它是文字、图片、视频等的混合体，最关键有超 链接，能从一个超文本跳转到另外一个超文本。OK，经过了对 HTTP 里这三个名词的详细解释，就可以给出比「超文本传输协议」这七个字更准确更 有技术含量的答案:HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据 的「约定和规范」。
### 问：什么是Restful API
一种新的API设计方法
缺点：无法批量查询
restful API设计之初时将URL当作一个唯一资源，所以根据URL无法进行批量查询
传统的API设计：把每个URL当作一个功能
Restful API设计：把每个URL当作唯一的资源
设计原则：
尽量不用URL参数：/api/list?page=2 => /api/list/2
用method表示操作类型：/api/update_blog?id=100（post请求） => /api/blog/100（patch请求）
### 2 . 1HTTP 报文结构

- [x] 报文格式
- [x] 常见首部字段
- [x] 常见状态码

[https://blog.csdn.net/yicixing7/article/details/79320821](https://blog.csdn.net/yicixing7/article/details/79320821)
[https://www.cnblogs.com/sunny-sl/p/6529830.html](https://www.cnblogs.com/sunny-sl/p/6529830.html)
#### 问:  什么是Http协议无状态协议?怎么解决Http协议无状态协议?

- **无状态协议对于事务处理没有记忆能力**。**缺少状态意味着如果后续处理需要前面的信息**
   - **也就是说，当客户端一次HTTP请求完成以后，客户端再发送一次HTTP请求，HTTP并不知道当前客户端是一个”老用户“。**
- **可以使用Cookie来解决无状态的问题，Cookie就相当于一个通行证，第一次访问的时候给客户端发送一个Cookie，当客户端再次来的时候，拿着Cookie(通行证)，那么服务器就知道这个是”老用户“。**
#### 问：HTTP请求报文与响应报文格式
请求报文包含四部分：
![](https://cdn.nlark.com/yuque/0/2021/png/12745046/1624799143628-545f5f79-9550-4fff-b585-df09b5110dcb.png#align=left&display=inline&height=272&id=u5dfa9be8&margin=%5Bobject%20Object%5D&originHeight=272&originWidth=735&status=done&style=none&width=735)

- a、请求行：包含请求方法、URI、HTTP版本信息
- b、请求首部字段
- c、请求内容实体
- d、空行

响应报文包含四部分：
![](https://cdn.nlark.com/yuque/0/2021/png/12745046/1624799143674-ca229940-c4a5-4ef5-bca3-c243389960d9.png#align=left&display=inline&height=260&id=u3fea995a&margin=%5Bobject%20Object%5D&originHeight=260&originWidth=724&status=done&style=none&width=724)

- a、状态行：包含HTTP版本、状态码、状态码的原因短语
- b、响应首部字段
- c、响应内容实体
- d、空行



#### 问：常见的首部字段
常见的首部：

- **通用首部字段（请求报文与响应报文都会使用的首部字段）**
   - Date：创建报文时间
   - Connection：连接的管理
   - Cache-Control：缓存的控制
   - Transfer-Encoding：报文主体的传输编码方式
- **请求首部字段（请求报文会使用的首部字段）**
   - Host：请求资源所在服务器
   - Accept：可处理的媒体类型
   - Accept-Charset：可接收的字符集
   - Accept-Encoding：可接受的内容编码
   - Accept-Language：可接受的自然语言
- **响应首部字段（响应报文会使用的首部字段）**
   - Accept-Ranges：可接受的字节范围
   - Location：令客户端重新定向到的URI
   - Server：HTTP服务器的安装信息
- **实体首部字段（请求报文与响应报文的的实体部分使用的首部字段）**
   - Allow：资源可支持的HTTP方法
   - Content-Type：实体主类的类型
   - Content-Encoding：实体主体适用的编码方式
   - Content-Language：实体主体的自然语言
   - Content-Length：实体主体的的字节数
   - Content-Range：实体主体的位置范围，一般用于发出部分请求时使用
#### 问：HTTP常见的状态码，有哪些？
![image.png](https://cdn.nlark.com/yuque/0/2021/png/12745046/1624798085970-bcd4b598-1516-435c-973c-895df8ab1130.png#align=left&display=inline&height=341&id=ub9b09aea&margin=%5Bobject%20Object%5D&name=image.png&originHeight=520&originWidth=1042&size=113433&status=done&style=none&width=683)

- 1xx

1xx 类状态码属于提示信息，是协议处理中的一种中间状态，实际用到的比较少。 2xx

- 2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。

「200 OK」是最常见的成功状态码，表示一切正常。如果是非 HEAD 请求，服务器返回的响应头  都会有 body 数据。
「204 No Content」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。
「206 Partial Content」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源 的全部，而是其中的一部分，也是服务器处理成功的状态。

- 3xx

3xx 类状态码表示客户端请求的资源发送了变动，需要客户端用新的 URL 重新发送请求获取资源， 也就是重定向。
「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。
「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。
  301 和 302 都会在响应头里使用字段 Location ，指明后续要跳转的 URL，浏览器会自动重定向新的URL。
「304 Not Modified」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，用于缓存控制。

- 4xx

4xx 类状态码表示客户端发送的报文有误，服务器无法处理，也就是错误码的含义。 「400 Bad Request」表示客户端请求的报文有错误，但只是个笼统的错误。
「403 Forbidden」表示服务器禁止访问资源，并不是客户端的请求出错。
「404 Not Found」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。 5xx

- 5xx 类状态码表示客户端请求报文正确，但是服务器处理时内部发生了错误，属于服务器端的错误 码。

「500 Internal Server Error」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并 不知道。 「501 Not Implemented」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。
「502 Bad Gateway」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问 后端服务器发生了错误。
「503 Service Unavailable」表示服务器当前很忙，暂时无法响应服务器，类似“网络服务正忙，请稍 后重试”的意思。
### 2 . 2 DNS缓存 /CDN缓存/HTTP缓存
[https://segmentfault.com/a/1190000017962411](https://segmentfault.com/a/1190000017962411)

- DNS缓存
- CDN缓存
- http缓存
   - 缓存位置
   - 缓存策略
#### 问：什么是DNS缓存

- **什么是DNS？**

全称 Domain Name System ,即域名系统。
万维网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。DNS协议运行在UDP协议之上，使用端口号53。

- **什么是DNS解析？**

简单的说,通过域名,最终得到该域名对应的IP地址的过程叫做域名解析（或主机名解析）。
www.dnscache.com (域名) - DNS解析 -> 11.222.33.444 (IP地址)

- **什么是DNS缓存？**

有dns的地方,就有缓存。浏览器、操作系统、Local DNS、根域名服务器，它们都会对DNS结果做一定程度的缓存。

- **DNS查询过程如下:**

首先搜索浏览器自身的DNS缓存,如果存在，则域名解析到此完成。
如果浏览器自身的缓存里面没有找到对应的条目，那么会尝试读取操作系统的hosts文件看是否存在对应的映射关系,如果存在，则域名解析到此完成。
如果本地hosts文件不存在映射关系，则查找本地DNS服务器(ISP服务器,或者自己手动设置的DNS服务器),如果存在,域名到此解析完成。
如果本地DNS服务器还没找到的话,它就会向根服务器发出请求,进行递归查询。
#### 问：什么是CDN 缓存？

- **什么是CDN？**

全称 Content Delivery Network,即内容分发网络。
通过对源网站资源的缓存，利用本身多台位于不同地域、不同运营商的服务器，向用户提供资就近访问的
功能。也就是说，用户的请求并不是直接发送给源网站，而是发送给 CDN 服务器，由 CND 服务器将请求定位到最近的含有该资源
的服务器上去请求。这样有利于提高网站的访问速度，同时通过这种方式也减轻了源服务器的访问压力。
摘录一个形象的比喻,来理解CDN是什么。
10年前，还没有火车票代售点一说，12306.cn更是无从说起。那时候火车票还只能在火车站的售票大厅购买，而我所在的小县城并不通火车，火车票都要去市里的火车站购买，而从我家到县城再到市里，来回就是4个小时车程，简直就是浪费生命。后来就好了，小县城里出现了火车票代售点，甚至乡镇上也有了代售点，可以直接在代售点购买火车票，方便了不少，全市人民再也不用在一个点苦逼的排队买票了。
简单的理解CDN就是这些代售点(缓存服务器)的承包商,他为买票者提供了便利,帮助他们在最近的地方(最近的CDN节点)用最短的时间(最短的请求时间)买到票(拿到资源),这样去火车站售票大厅排队的人也就少了。也就减轻了售票大厅的压力(起到分流作用,减轻服务器负载压力)。
用户在浏览网站的时候，CDN会选择一个离用户最近的CDN边缘节点来响应用户的请求，这样海南移动用户的请求就不会千里迢迢跑到北京电信机房的服务器（假设源站部署在北京电信机房）上了。

- **什么是CDN缓存？**

关于CDN缓存,在浏览器本地缓存失效后,浏览器会向CDN边缘节点发起请求。类似浏览器缓存,CDN边缘节点也存在着一套缓存机制。CDN边缘节点缓存策略因服务商不同而不同，但一般都会遵循http标准协议，通过http响应头中的
Cache-control: max-age //后面会提到
的字段来设置CDN边缘节点数据缓存时间。
当浏览器向CDN节点请求数据时，CDN节点会判断缓存数据是否过期，若缓存数据并没有过期，则直接将缓存数据返回给客户端；否则，CDN节点就会向服务器发出回源请求，从服务器拉取最新数据，更新本地缓存，并将最新数据返回给客户端。 CDN服务商一般会提供基于文件后缀、目录多个维度来指定CDN缓存时间，为用户提供更精细化的缓存管理。

- **CDN 有什么优势？**

CDN节点解决了跨运营商和跨地域访问的问题，访问延时大大降低。
大部分请求在CDN边缘节点完成，CDN起到了分流作用，减轻了源服务器的负载。

- CDN 有什么缺点？
   - 当网站更新时，如果CDN节点上数据没有及时更新，即便用户再浏览器使用Ctrl +F5的方式使浏览器端的缓存失效，也会因为CDN边缘节点没有同步最新数据而导致用户访问异常。
#### 问：缓存位置都有哪些？

- Service Worker缓存
   - Service Worker是独立运行在浏览器里面的线程，是一个可以自由控制缓存文件的机制，并且缓存是持续性的。

      当 Service Worker 没有命中缓存的时候，我们需要去调用 fetch 函数获取数据。

- Memory Cache 内存存储
   - 内存中的缓存，读取内存中的数据肯定比磁盘快。内存直接由 CPU 控制。

     但是内存缓存虽然读取高效，可是缓存持续性很短，会随着进程的释放而释放。  一旦我们关闭 Tab 页面，内存中的缓存也就被释放了

- Disk Cache 磁盘缓存
   - 容量大，时效长，当退出进程时，内存中的数据会被清空，而磁盘的数据不会，所以，当下次再进入该进程时，该进程仍可以从diskCache中获得数据，而Memory Cache则不行。
- Push Cache 推送缓存
   - 是 HTTP/2 中的内容，当另外三种缓存都没有命中时，它才会被使用。它只在会话（Session）中存在，一旦会话结束就被释放，并且缓存时间也很短暂。
#### 问：缓存读取的原理
先从内存中查找对应的缓存，如果内存中能找到就读取对应的缓存，否则的话就从硬盘中查找对应的缓存，如果有就读取，否则的话，就重新网络请求（这个时候如果有CDN的话，就会去请求CDN边缘节点）。
#### 问：内存缓存与硬盘缓存的区别

- 内存缓存：读取快速，会将编译解析后的文件，直接存入该进程的内存中，占据该进程一定的内存资源。但是缓存时效性很短，会随着进程的释放而释放。
- 硬盘缓存：硬盘缓存则是直接将缓存写入硬盘文件中，读取缓存需要对该缓存存放的硬盘文件进行I/O操作，然后重新解析该缓存内容，读取复杂，速度比内存缓存慢。
#### 问：我们是不是能让数据都存放在内存中呢？
计算机中的内存一定比硬盘容量小得多，操作系统需要精打细算内存的使用，所以能让我们使用的内存必然不多。
#### 问：浏览器会把哪些文件丢进内存中？哪些丢进硬盘中？
对于大文件来说，大概率是不存储在内存中的，反之优先。当前系统内存使用率高的话，文件优先存储进硬盘。
在浏览器中，浏览器会在js和图片等文件解析执行后直接存入内存缓存中，那么当刷新页面时只需直接从内存缓存中读取(from memory cache)；而css文件则会存入硬盘文件中，所以每次渲染页面都需要从硬盘读取缓存(from disk cache)。
#### 问：为什么一般js和图片文件会放到内存缓存，css 放在硬盘缓存？
样式表一般在磁盘中，不会缓存到内存中去，因为CSS样式加载一次即可渲染出网页。但是，脚本却可能随时会执行，如果脚本在磁盘当中，在执行该脚本需要从磁盘中取到内存当中来。这样的IO开销是比较大的，有可能会导致浏览器失去响应。因此，脚本一般在内存中。
#### 问：描述一下http的缓存机制/缓存策略/缓存的规则
缓存策略都是通过设置 HTTP Header 来实现的,我们将缓存分为强缓存和协商缓存

- 强缓存
   - 强缓存表示在缓存期间不需要请求，state code 为 200
   - 服务器响应的header中会用两个字段来表明——Expires和Cache-Control
      - **Expires**

Exprires的值为服务端返回的数据到期时间。当再次请求时的请求时间小于返回的此时间，则直接使用缓存数据。受限于本地时间，如果修改了本地时间，可能有误差，另一方面，Expires是HTTP1.0的产物，故现在大多数使用Cache-Control替代。

      - **Cache-Control**

Cache-Control优先级高于 Expires，它有很多属性，不同的属性代表的意义也不同。
private：客户端可以缓存
public：客户端和代理服务器都可以缓存
max-age=t：缓存内容将在t秒后失效
no-cache：需要使用协商缓存来验证缓存数据
no-store：所有内容都不会缓存。

- 协商缓存
   - 如果缓存过期了，就需要发起请求验证资源是否有更新，当浏览器发起请求验证资源时，如果资源没有做改变，那么服务端就会返回 304 状态码，并且更新浏览器缓存有效期
   - 服务器响应的header中会用两个字段来表明——ETag 和 Last-Modified
      - ETag
         - 类似于文件指纹，If-None-Match 会将当前 ETag 发送给服务器，询问该资源 ETag 是否变动，有变动的话就将新的资源发送回来。并且 ETag 优先级比 Last-Modified 高
      - Last-Modified
         - 本地文件最后修改日期，If-Modified-Since（校验请求） 会将 Last-Modified 的值发送给服务器，询问服务器在该日期后资源是否有更新，有更新的话就会将新的资源发送回来，否则返回 304 状态码
         - 弊端：
            - 如果本地打开缓存文件，即使没有对文件进行修改，但还是会造成 Last-Modified 被修改，服务端不能命中缓存导致发送相同的资源
            - 因为 Last-Modified 只能以秒计时，如果在不可感知的时间内修改完成文件，那么服务端会认为资源还是命中了，不会返回正确的资源
#### 问：介绍下304过程
a. 浏览器请求资源时首先命中资源的Expires 和 Cache-Control，Expires 受限于本地时间，如果修改了本地时间，可能会造成缓存失效，可以通过Cache-control: max-age指定最大生命周期，状态仍然返回200，但不会请求数据，在浏览器中能明显看到from cache字样。
b. 强缓存失效，进入协商缓存阶段，首先验证ETagETag可以保证每一个资源是唯一的，资源变化都会导致ETag变化。服务器根据客户端上送的If-None-Match值来判断是否命中缓存。
c. 协商缓存Last-Modify/If-Modify-Since阶段，客户端第一次请求资源时，服务服返回的header中会加上Last-Modify，Last-modify是一个时间标识该资源的最后修改时间。再次请求该资源时，request的请求头中会包含If-Modify-Since，该值为缓存之前返回的Last-Modify。服务器收到If-Modify-Since后，根据资源的最后修改时间判断是否命中缓存。
#### 问：用户输入 URL 到浏览器显示页面，这个过程发生了什么？
   （1）首先会对 URL 进行解析，分析所需要使用的传输协议和请求的资源的路径。如果输入的 URL 中的协议或者主机名不合法，
       将会把地址栏中输入的内容传递给搜索引擎。如果没有问题，浏览器会检查 URL 中是否出现了非法字符，如果存在非法字
       符，则对非法字符进行转义后再进行下一过程。
   （2）浏览器会判断所请求的资源是否在缓存里，如果请求的资源在缓存里并且没有失效，那么就直接使用，否则向服务器发起新
       的请求。
   （3）下一步我们首先需要获取的是输入的 URL 中的域名的 IP 地址，首先会判断本地是否有该域名的 IP 地址的缓存，如果
       有则使用，如果没有则向本地 DNS 服务器发起请求。本地 DNS 服务器也会先检查是否存在缓存，如果没有就会先向根域
       名服务器发起请求，获得负责的顶级域名服务器的地址后，再向顶级域名服务器请求，然后获得负责的权威域名服务器的地
       址后，再向权威域名服务器发起请求，最终获得域名的 IP 地址后，本地 DNS 服务器再将这个 IP 地址返回给请求的用
       户。用户向本地 DNS 服务器发起请求属于递归请求，本地 DNS 服务器向各级域名服务器发起请求属于迭代请求。
   （4）当浏览器得到 IP 地址后，数据传输还需要知道目的主机 MAC 地址，因为应用层下发数据给传输层，TCP 协议会指定源
       端口号和目的端口号，然后下发给网络层。网络层会将本机地址作为源地址，获取的 IP 地址作为目的地址。然后将下发给
       数据链路层，数据链路层的发送需要加入通信双方的 MAC 地址，我们本机的 MAC 地址作为源 MAC 地址，目的 MAC 地
       址需要分情况处理，通过将 IP 地址与我们本机的子网掩码相与，我们可以判断我们是否与请求主机在同一个子网里，如果
       在同一个子网里，我们可以使用 APR 协议获取到目的主机的 MAC 地址，如果我们不在一个子网里，那么我们的请求应该
       转发给我们的网关，由它代为转发，此时同样可以通过 ARP 协议来获取网关的 MAC 地址，此时目的主机的 MAC 地址应
       该为网关的地址。
   （5）下面是 TCP 建立连接的三次握手的过程，首先客户端向服务器发送一个 SYN 连接请求报文段和一个随机序号，服务端接
       收到请求后向服务器端发送一个 SYN ACK报文段，确认连接请求，并且也向客户端发送一个随机序号。客户端接收服务器的
       确认应答后，进入连接建立的状态，同时向服务器也发送一个 ACK 确认报文段，服务器端接收到确认后，也进入连接建立
       状态，此时双方的连接就建立起来了。
   （6）如果使用的是 HTTPS 协议，在通信前还存在 TLS 的一个四次握手的过程。首先由客户端向服务器端发送使用的协议的版
       本号、一个随机数和可以使用的加密方法。服务器端收到后，确认加密的方法，也向客户端发送一个随机数和自己的数字证
       书。客户端收到后，首先检查数字证书是否有效，如果有效，则再生成一个随机数，并使用证书中的公钥对随机数加密，然后
       发送给服务器端，并且还会提供一个前面所有内容的 hash 值供服务器端检验。服务器端接收后，使用自己的私钥对数据解
       密，同时向客户端发送一个前面所有内容的 hash 值供客户端检验。这个时候双方都有了三个随机数，按照之前所约定的加
       密方法，使用这三个随机数生成一把秘钥，以后双方通信前，就使用这个秘钥对数据进行加密后再传输。
   （7）当页面请求发送到服务器端后，服务器端会返回一个 html 文件作为响应，浏览器接收到响应后，开始对 html 文件进行
       解析，开始页面的渲染过程。
   （8）浏览器首先会根据 html 文件构建 DOM 树，根据解析到的 css 文件构建 CSSOM 树，如果遇到 script 标签，则判端
       是否含有 defer 或者 async 属性，要不然 script 的加载和执行会造成页面的渲染的阻塞。当 DOM 树和 CSSOM 树建
       立好后，根据它们来构建渲染树。渲染树构建好后，会根据渲染树来进行布局。布局完成后，最后使用浏览器的 UI 接口对页
       面进行绘制。这个时候整个页面就显示出来了。
   （9）最后一步是 TCP 断开连接的四次挥手过程。
#### 问：如果什么缓存策略都没设置，那么浏览器会怎么处理？
对于这种情况，浏览器会采用一个启发式的算法，通常会取响应头中的 Date 减去 Last-Modified 值的 10% 作为缓存时间。
#### 
### 2 . 3HTTP 方法

- 着重对比 GET、POST



#### 问：常用的HTTP方法有哪些？


- GET： 用于请求访问已经被URI（统一资源标识符）识别的资源，可以通过URL传参给服务器
- POST：用于传输信息给服务器，主要功能与GET方法类似，但一般推荐使用POST方式。
- PUT： 传输文件，报文主体中包含文件内容，保存到对应URI位置。
- HEAD： 获得报文首部，与GET方法类似，只是不返回报文主体，一般用于验证URI是否有效。
- DELETE：删除文件，与PUT方法相反，删除对应URI位置的文件。
- OPTIONS：查询相应URI支持的HTTP方法。
#### 问：说一下 GET 和 POST 的区别？
 
**区别一：**
get重点在从服务器上获取资源，post重点在向服务器发送数据；
**区别二：**
get传输数据是通过URL请求，以field（字段）= value的形式，置于URL后，并用"?"连接，多个请求数据间用"&"连接，如[http://127.0.0.1/Test/login.action?name=admin&password=admin](http://127.0.0.1/Test/login.action?name=admin&password=admin)，这个过程用户是可见的；
post传输数据通过Http的post机制，将字段与对应值封存在请求实体中发送给服务器，这个过程对用户是不可见的；
**区别三：**
Get传输的数据量小，因为受URL长度限制，但效率较高；
Post可以传输大量数据，所以上传文件时只能用Post方式；
**区别四：**
get是不安全的，因为URL是可见的，可能会泄露私密信息，如密码等；
post较get安全性较高；
**区别五：**
get方式只能支持ASCII字符，向服务器传的中文字符可能会乱码。
post支持标准字符集，可以正确传递中文字符。


#### 问：GET 和 POST 方法都是安全和幂等的吗？
先说明下安全和幂等的概念：
在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。
所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。
那么很明显 **GET 方法就是安全且幂等的**，因为它是「只读」操作，无论操作多少次，服务器上的数据
都是安全的，且每次的结果都是相同的。
**POST **因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是**不安全**的，且多次提交数据
就会创建多个资源，所以**不是幂等**的。
#### 问：http 请求方法 options 方法有什么用？
  OPTIONS 请求与 HEAD 类似，一般也是用于客户端查看服务器的性能。这个方法会请求服务器返回该资源所支持的所有 HTTP 请
  求方法，该方法会用'*'来代替资源名称，向服务器发送 OPTIONS 请求，可以测试服务器功能是否正常。JS 的 XMLHttpRequest
  对象进行 CORS 跨域资源共享时，对于复杂请求，就是使用 OPTIONS 方法发送嗅探请求，以判断是否有对指定资源的访问权限。
### 2 . 4各种解决跨域的方法
#### 问：什么是同源策略？
同源策略，它是由Netscape提出的一个著名的安全策略。现在所有支持JavaScript 的浏览器都会使用这个策略来对脚本和请求进行校验，若不同源，则禁止使用
#### 问：那如何判断是否同源？
主要根据三个维度，域名，协议，端口三个都相同才算同源。
#### 问：同源策略有什么作用/限制内容？
①无法用js读取非同源的Cookie、LocalStorage 和 IndexDB
这个主要是为了防止恶意网站通过js获取用户其他网站的cookie等用户信息。
②无法用js获取非同源的DOM
防止恶意网站通过iframe获取页面dom，从而窃取页面的信息。
③无法用js发送非同源的AJAX请求
防止恶意的请求攻击服务器窃取数据信息。
#### 问：解决跨域请求问题的方法都有哪些？
1、 通过jsonp跨域 2、 document.domain + iframe跨域 3、 location.hash + iframe 4、 window.name + iframe跨域 5、 postMessage跨域 6、 跨域资源共享（CORS） 7、 nginx代理跨域 8、 nodejs中间件代理跨域 9、 WebSocket协议跨域
### 2.5HTTP 内容安全策略

- CORS
- CSP - 新的
#### HTTP 控制访问CORS
#### 问：什么是CORS？
CORS是一个w3c标准,全称是"跨域资源共享"(Cross-origin resource sharing),但一个请求url的协议,域名,端口三者之间任意与当前页面地址不同即为跨域.它允许阅览器向跨源服务器发送XMLHttpRequest请求,从而克服AJAX只能同源使用的限制.浏览器默认的安全限制为同源策略，即JavaScript或Cookie只能访问同源（相同协议，相同域名，相同端口）下的内容。但由于跨域访问资源需要，出现了CORS机制，这种机制让web服务器能跨站访问控制，使跨站数据传输更安全。CORS需要阅览器和服务器同时支持，目前，主流的阅览器都支持cors。
浏览器将CORS请求分为两类：简单请求和非简单请求；

- 简单请求
   - 1.1 区分条件：

只要满足一下两大条件，属于简单请求：
（1) 请求方法是以下三种方法之一：
        HEAD
        GET
        POST
（2）HTTP的头信息不超出以下几种字段：
        Accept
        Accept-Language
        Content-Language
        Last-Event-ID
        Content-Type：只限于三个值application/x-www-form-urlencoded、multipart/form-data、text/plain        
不同时满足上面两个条件，就是非简单请求

- 非简单请求
   - 当不同时满足区分条件的，就是非简单请求。

2.1 预检请求
非简单请求的CORS请求，会在正式通信前进行一次Http查询请求，又称预检请求。
浏览器先请求服务器，当前网页所在域名是否在服务器许可名单中以及可以使用那些HTTP动词和头信息字段，当客户端得到肯定答复时，浏览器才会正式发出XMLHttpRequest请求。
预检请求用的请求方法是OPTIONS,表示这个请求是用来询问服务器支持什么请求方法的。
"预检"请求的头信息包括两个特殊字段。
Access-Control-Request-Method:该字段是必须的，用来列出浏览器的CORS请求会用到哪些HTTP方法。
Access-Control-Request-Headers:该字段是一个逗号分割的字符串，指定浏览器CORS请求会额外发送的头信息字段。
2.2 浏览器的正常请求和回应
一旦服务器通过了"预检"请求，以后每次浏览器正常的CORS请求，就都跟简单请求一样，会有一个Origin头信息字段。服务器的回应，也都会有一个Access-Control-Allow-Origin头信息字段。
#### 问：什么是CSP？
CSP指的是内容安全策略，为了缓解很大一部分潜在的跨站脚本问题，浏览器的扩展程序系统引入了内容安全策略（CSP）的一般概念。这将引入一些相当严格的策略，会使扩展程序在默认情况下更加安全，开发者可以创建并强制应用一些规则，管理网站允许加载的内容。简单来说，就是我们能够规定，我们的网站只接受我们指定的请求资源。
CSP 的实质就是白名单制度，开发者明确告诉客户端，哪些外部资源可以加载和执行，等同于提供白名单。它的实现和执行全部由浏览器完成，开发者只需提供配置。CSP 大大增强了网页的安全性。攻击者即使发现了漏洞，也没法注入脚本，除非还控制了一台列入了白名单的可信主机。
（1）`Content-Security-Policy`
配置好并启用后，不符合 CSP 的外部资源就会被阻止加载。
（2）`Content-Security-Policy-Report-Only`
表示不执行限制选项，只是记录违反限制的行为。它必须与`report-uri`选项配合使用。


### 2.6 HTTP与HTTPS
#### 问：HTTP 与 HTTPS 有哪些区别？
1. HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全
的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
2. HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP
三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
3. HTTP 的端口号是 80，HTTPS 的端口号是 443。 
4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。
#### 问：HTTPS 解决了 HTTP 的哪些问题？
HTTP 由于是明文传输，所以安全上存在以下三个风险： 
**窃听风险**，比如通信链路上可以获取通信内容，用户号容易没。 
**篡改风险**，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。 
**冒充风险**，比如冒充淘宝网站，用户钱容易没。
HTTP**S **在 HTTP 与 TCP 层之间加入了 SSL/TLS 协议，可以很好的解决了上述的风险： 
**信息加密**：交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。 
**校验机制**：无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾 
广告。 
**身份证书**：证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。
![image.png](https://cdn.nlark.com/yuque/0/2021/png/12745046/1625040107096-7ffb9de7-b8a8-41cc-aa18-70fea1b537d3.png#align=left&display=inline&height=396&id=u5d187ff7&margin=%5Bobject%20Object%5D&name=image.png&originHeight=577&originWidth=1209&size=274686&status=done&style=none&width=830)
#### 问：HTTPS 是如何解决上面的三个风险的？

- 混合加密

**混合加密**的方式实现信息的**机密性**，解决了窃听的风险。 
HTTPS 采用的是**对称加密**和**非对称加密**结合的「混合加密」方式： 在通信建立前采用**非对称加密**的方式交换「会话秘钥」，后续就不再使用非对称加密。 在通信过程中全部使用**对称加密**的「会话秘钥」的方式加密明文数据。 采用「混合加密」的方式的原因： 
**对称加密**只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。 
**非对称加密**使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但 
速度慢。

- **摘要算法**

**摘要算法**的方式来实现**完整性**，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。 
客户端在发送明文之前会通过摘要算法算出明文的「指纹」，发送的时候把「指纹 + 明文」一同加密成密文后，发送给服务器，服务器解密后，用相同的摘要算法算出发送过来的明文，通过比较客户端携带 的「指纹」和当前算出的「指纹」做比较，若「指纹」相同，说明数据是完整的。

- **数字证书**

将服务器公钥放入到**数字证书**中，解决了冒充的风险。
如何保证公钥不被篡改和信任度？ 
所以这里就需要借助第三方权威机构 CA （数字证书认证机构），将**服务器公钥放在数字证书**（由数 
字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。
#### 问：HTTPS 是如何建立连接的？其间交互了什么？
SSL/TLS 协议基本流程： 
客户端向服务器索要并验证服务器的公钥。 
双方协商生产「会话秘钥」。 
双方采用「会话秘钥」进行加密通信。
SSL/TLS 协议建立的详细流程： 
_1. ClientHello _
首先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。 
在这一步，客户端主要向服务器发送以下信息： 
（1）客户端支持的 SSL/TLS 协议版本，如 TLS 1.2 版本。 
（2）客户端生产的随机数（ Client Random ），后面用于生产「会话秘钥」。 
（3）客户端支持的密码套件列表，如 RSA 加密算法。 
_2. SeverHello _
服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello 。服务器回应的内容有如下内容： 
（1）确认 SSL/ TLS 协议版本，如果浏览器不支持，则关闭加密通信。 
（2）服务器生产的随机数（ Server Random ），后面用于生产「会话秘钥」。 
（3）确认的密码套件列表，如 RSA 加密算法。 
（4）服务器的数字证书。 
_3._客户端回应 
客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的 
真实性。 
如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如 
下信息： 
（1）一个随机数（ pre-master key ）。该随机数会被服务器公钥加密。 
（2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。 
（3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数 
据做个摘要，用来供服务端校验。 
上面第一项的随机数是整个握手阶段的第三个随机数，这样服务器和客户端就同时有三个随机数，接着 
就用双方协商的加密算法，**各自生成**本次通信的「会话秘钥」。 
_4. _服务器的最后回应 
服务器收到客户端的第三个随机数（ pre-master key ）之后，通过协商的加密算法，计算出本次通信的 
「会话秘钥」。然后，向客户端发生最后的信息： 
（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数 
据做个摘要，用来供客户端校验。 
至此，整个 SSL/TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普 
通的 HTTP 协议，只不过用「会话秘钥」加密内容。
#### 问： TLS/SSL 中什么一定要用三个随机数，来生成"会话密钥"？


```
客户端和服务器都需要生成随机数，以此来保证每次生成的秘钥都不相同。使用三个随机数，是因为 SSL 的协议默认不信任每个主
机都能产生完全随机的数，如果只使用一个伪随机的数来生成秘钥，就很容易被破解。通过使用三个随机数的方式，增加了自由度，
一个伪随机可能被破解，但是三个伪随机就很接近于随机了，因此可以使用这种方法来保持生成秘钥的随机性和安全性。
```


#### 问：SSL 连接断开后如何恢复？


```
一共有两种方法来恢复断开的 SSL 连接，一种是使用 session ID，一种是 session ticket。

使用 session ID 的方式，每一次的会话都有一个编号，当对话中断后，下一次重新连接时，只要客户端给出这个编号，服务器
如果有这个编号的记录，那么双方就可以继续使用以前的秘钥，而不用重新生成一把。目前所有的浏览器都支持这一种方法。但是
这种方法有一个缺点是，session ID 只能够存在一台服务器上，如果我们的请求通过负载平衡被转移到了其他的服务器上，那
么就无法恢复对话。

另一种方式是 session ticket 的方式，session ticket 是服务器在上一次对话中发送给客户的，这个 ticket 是加密的
，只有服务器能够解密，里面包含了本次会话的信息，比如对话秘钥和加密方法等。这样不管我们的请求是否转移到其他的服务器
上，当服务器将 ticket 解密以后，就能够获取上次对话的信息，就不用重新生成对话秘钥了。
```


#### 问： RSA 算法的安全性保障？


```
对极大整数做因数分解的难度决定了 RSA 算法的可靠性。换言之，对一极大整数做因数分解愈困难，RSA 算法愈可靠。现在102
4位的 RSA 密钥基本安全，2048位的密钥极其安全。
```
### HTTP版本演进

- HTTP1.1 现在常用的
- HTTP2 有哪些改进国内还没用就快过时了
- HTTP3 又有哪些改进
#### 问：说说 HTTP/1.1 相比 HTTP/1.0 提高了什么性能？
HTTP/1.1 相比 HTTP/1.0 性能上的改进： 

- 使用 TCP 长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。 
- 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求 

出去，可以减少整体的响应时间。 
但 HTTP/1.1 还是有性能瓶颈： 

- 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 Body 的部分； 

发送冗长的首部。每次互相发送相同的首部造成的浪费较多； 

- 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队 

头阻塞； 

- 没有请求优先级控制； 

请求只能从客户端开始，服务器只能被动响应。
#### 问：那上面的 HTTP/1.1 的性能瓶颈，HTTP/2 做了什么优化？
HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。 
那 HTTP/2 相比 HTTP/1.1 性能上的改进： 
_1. _头部压缩 
HTTP/2 会**压缩头**（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会 
帮你**消除重复的部分**。 
这就是所谓的 HPACK 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表， 
生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就**提高速度**了。 
_2. _二进制格式 
HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了**二进制格式**，头信息和数据体都是 
二进制，并且统称为帧（frame）：**头信息帧和数据帧**。
这样虽然对人不友好，但是对计算机非常友好，因为计算机只懂二进制，那么收到报文后，无需再将明 
文的报文转成二进制，而是直接解析二进制报文，这**增加了数据传输的效率**。
![image.png](https://cdn.nlark.com/yuque/0/2021/png/12745046/1625057337316-6d1c88bc-b328-47c9-b1f6-60ffe6426aad.png#align=left&display=inline&height=304&id=uee51b04e&margin=%5Bobject%20Object%5D&name=image.png&originHeight=552&originWidth=987&size=87713&status=done&style=none&width=543)
_3. _数据流 
HTTP/2 的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必 
须要对数据包做标记，指出它属于哪个回应。 
每个请求或回应的所有数据包，称为一个数据流（ Stream ）。每个数据流都标记着一个独一无二的编 
号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数 
客户端还可以**指定数据流的优先级**。优先级高的请求，服务器就先响应该请求。
_4. _多路复用 
HTTP/2 是可以在**一个连接中并发多个请求或回应，而不用按照顺序一一对应**。移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会再出现「队头阻塞」问题，**降低了延迟， **
**大幅度提高了连接的利用率**。 
举例来说，在一个 TCP 连接里，服务器收到了客户端 A 和 B 的两个请求，如果发现 A 处理过程非常耗 
时，于是就回应 A 请求已经处理好的部分，接着回应 B 请求，完成后，再回应 A 请求剩下的部分。
_5. _服务器推送 
HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以**主动 **
向客户端发送消息。 
举例来说，在浏览器刚请求 HTML 的时候，就提前把可能会用到的 JS、CSS 文件等静态资源主动发给 
客户端，**减少延时的等待**，也就是服务器推送（Server Push，也叫 Cache Push）。
#### 问：HTTP/2 有哪些缺陷？HTTP/3 做了哪些优化？
HTTP/2 主要的问题在于，多个 HTTP 请求在复用一个 TCP 连接，下层的 TCP 协议是不知道有多少个 
HTTP 请求的。所以一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的**所有 **
**的 HTTP 请求都必须等待这个丢了的包被重传回来**。 
HTTP/1.1 中的管道（ pipeline）传输中如果有一个请求阻塞了，那么队列后请求也统统被阻塞住 了 
HTTP/2 多个请求复用一个TCP连接，一旦发生丢包，就会阻塞住所有的 HTTP 请求。 
这都是基于 TCP 传输层的问题，所以 **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！**
UDP 发生是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1 的队头阻塞 和 HTTP/2 的一个丢包全部重传问题。
### Quic 协议
QUIC 是一个在 UDP 之上的伪 TCP + TLS + HTTP/2 的多路复用的协议。
大家都知道 UDP 是不可靠传输的，但基于 UDP 的 **QUIC 协议 **可以实现类似 TCP 的可靠性传输。 
QUIC 有自己的一套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流，**其他 流不会受到影响**。 
TLS3 升级成了最新的 1.3 版本，头部压缩算法也升级成了 QPack 。 
HTTPS 要建立一个连接，要花费 6 次交互，先是建立三次握手，然后是 TLS/1.3 的三次握手。 
QUIC 直接把以往的 TCP 和 TLS/1.3 的 6 次交互**合并成了 3 次，减少了交互次数**。
![image.png](https://cdn.nlark.com/yuque/0/2021/png/12745046/1625058319730-d980599b-ed10-4f78-9286-a970e7894feb.png#align=left&display=inline&height=477&id=ufeb8ff4e&margin=%5Bobject%20Object%5D&name=image.png&originHeight=714&originWidth=1147&size=591397&status=done&style=none&width=766)
所以， QUIC 是一个在 UDP 之上的**伪** TCP + TLS + HTTP/2 的多路复用的协议。 
QUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问 
题。所以 HTTP/3 现在普及的进度非常的缓慢，不知道未来 UDP 是否能够逆袭 TCP。
### 正向代理和反向代理
#### 问：什么是正向代理和反向代理？
   我们常说的代理也就是指正向代理，正向代理的过程，它隐藏了真实的请求客户端，服务端不知道真实的客户端是谁，客户端请求的
   服务都被代理服务器代替来请求。
   反向代理隐藏了真实的服务端，当我们请求一个网站的时候，背后可能有成千上万台服务器为我们服务，但具体是哪一台，我们不知
   道，也不需要知道，我们只需要知道反向代理服务器是谁就好了，反向代理服务器会帮我们把请求转发到真实的服务器那里去。反向
   代理器一般用来实现负载平衡。
#### 问：负载平衡的两种实现方式？
   一种是使用反向代理的方式，用户的请求都发送到反向代理服务上，然后由反向代理服务器来转发请求到真实的服务器上，以此来实
   现集群的负载平衡。
   另一种是 DNS 的方式，DNS 可以用于在冗余的服务器上实现负载平衡。因为现在一般的大型网站使用多台服务器提供服务，因此一
   个域名可能会对应多个服务器地址。当用户向网站域名请求的时候，DNS 服务器返回这个域名所对应的服务器 IP 地址的集合，但在
   每个回答中，会循环这些 IP 地址的顺序，用户一般会选择排在前面的地址发送请求。以此将用户的请求均衡的分配到各个不同的服
   务器上，这样来实现负载均衡。这种方式有一个缺点就是，由于 DNS 服务器中存在缓存，所以有可能一个服务器出现故障后，域名解
   析仍然返回的是那个 IP 地址，就会造成访问的问题。
### Websocket
#### 问：即时通讯的实现，短轮询、长轮询、SSE 和 WebSocket 间的区别
    短轮询和长轮询的目的都是用于实现客户端和服务器端的一个即时通讯。


    短轮询的基本思路就是浏览器每隔一段时间向浏览器发送 http 请求，服务器端在收到请求后，不论是否有数据更新，都直接进行
    响应。这种方式实现的即时通信，本质上还是浏览器发送请求，服务器接受请求的一个过程，通过让客户端不断的进行请求，使得客
    户端能够模拟实时地收到服务器端的数据的变化。这种方式的优点是比较简单，易于理解。缺点是这种方式由于需要不断的建立 ht
    tp 连接，严重浪费了服务器端和客户端的资源。当用户增加时，服务器端的压力就会变大，这是很不合理的。


    长轮询的基本思路是，首先由客户端向服务器发起请求，当服务器收到客户端发来的请求后，服务器端不会直接进行响应，而是先将
    这个请求挂起，然后判断服务器端数据是否有更新。如果有更新，则进行响应，如果一直没有数据，则到达一定的时间限制才返回。
    客户端 JavaScript 响应处理函数会在处理完服务器返回的信息后，再次发出请求，重新建立连接。长轮询和短轮询比起来，它的
    优点是明显减少了很多不必要的 http 请求次数，相比之下节约了资源。长轮询的缺点在于，连接挂起也会导致资源的浪费。


    SSE 的基本思想是，服务器使用流信息向服务器推送信息。严格地说，http 协议无法做到服务器主动推送信息。但是，有一种变通
    方法，就是服务器向客户端声明，接下来要发送的是流信息。也就是说，发送的不是一次性的数据包，而是一个数据流，会连续不断
    地发送过来。这时，客户端不会关闭连接，会一直等着服务器发过来的新的数据流，视频播放就是这样的例子。SSE 就是利用这种机
    制，使用流信息向浏览器推送信息。它基于 http 协议，目前除了 IE/Edge，其他浏览器都支持。它相对于前面两种方式来说，不
    需要建立过多的 http 请求，相比之下节约了资源。


    上面三种方式本质上都是基于 http 协议的，我们还可以使用 WebSocket 协议来实现。WebSocket 是 Html5 定义的一个新协
    议，与传统的 http 协议不同，该协议允许由服务器主动的向客户端推送信息。使用 WebSocket 协议的缺点是在服务器端的配置
    比较复杂。WebSocket 是一个全双工的协议，也就是通信双方是平等的，可以相互发送消息，而 SSE 的方式是单向通信的，只能
    由服务器端向客户端推送信息，如果客户端需要发送信息就是属于下一个 http 请求了。
### 共享登录状态
#### 问：怎么实现多个网站之间共享登录状态
    在多个网站之间共享登录状态指的就是单点登录。多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。
    我认为单点登录可以这样来实现，首先将用户信息的验证中心独立出来，作为一个单独的认证中心，该认证中心的作用是判断客户端发
    送的账号密码的正确性，然后向客户端返回对应的用户信息，并且返回一个由服务器端秘钥加密的登录信息的 token 给客户端，该
    token 具有一定的有效时限。当一个应用系统跳转到另一个应用系统时，通过 url 参数的方式来传递 token，然后转移到的应用站
    点发送给认证中心，认证中心对 token 进行解密后验证，如果用户信息没有失效，则向客户端返回对应的用户信息，如果失效了则将
    页面重定向会单点登录页面。
### RPC 远程过程调用
 
RPC(Remote Procedure Call):远程过程调用。一种通过网络从远程计算机上请求服务，而不需要了解底层网络技术的协议。在 OSI 网络七层模型中，RPC 跨越了传输层和应用层，RPC 使得开发，包括网络分布式多程序在内的应用程序更加容易。


主流的 RPC 框架分为基于 HTTP 和基于 TCP 的两种。基于 HTTP 的 RPC调用很简单，就和ajax类似，返回结果更单一（JSON 或 XML）。它的优点在于实现简单，标准化和跨语言，比较适合对外提供 OpenAPI 的场景，而它的缺点是 HTTP 协议传输效率较低、短连接开销较大（HTTP 2.0 后有很大改进）。


基于 TCP 的 RPC 调用（后面都单指这种），由于 TCP 协议处于协议栈的下层，能够更加灵活地对协议字段进行定制，减少网络开销，提高性能，实现更大的吞吐量和并发数。但是需要更多地关注底层复杂的细节，跨语言和跨平台难度大，实现的代价更高，它比较适合内部系统之间追求极致性能的场景。


- 在传输层，基于 TPC/UDP 等，为通信程序之间携带信息数据。
- 在应用层，一般不使用HTTP，二十更高性能的二进制协议。也不使用DNS寻址，而是通过寻址服务器寻址。


对比 ajax & rpc


- Ajax
DNS寻址: 域名 -> DNS服务器 -> IP
应用层: HTTP协议。文本格式比如 html，json
传输层：TCP


- RPC
内网寻址: 专有的服务。RPC后台大多运行在内网，用一个标识符比如ID，请求内网寻址服务器，返回IP。得到IP后就可以向目标服务器请求数据了
应用层: 二进制协议。约定格式的二进制文本，包体积小，二进制更有利于计算机的处理，编解码速率高
传输层：TCP/UDP， 比如 TCP的 单工、半双工、全双工通信（实现难度和成本考虑）


## 3. 传输层 TCP、UDP
传输层协议主要是为不同主机上的不同进程间提供了逻辑通信的功能。传输层只工作在端系统中。
### 多路复用与多路分解
将传输层报文段中的数据交付到正确的套接字的工作被称为多路分解。


在源主机上从不同的套接字中收集数据，封装头信息生成报文段后，将报文段传递到网络层，这个过程被称为多路复用。


无连接的多路复用和多路分解指的是 UDP 套接字的分配过程，一个 UDP 套接字由一个二元组来标识，这个二元组包含了一
个目的地址和一个目的端口号。因此不同源地址和端口号的 UDP 报文段到达主机后，如果它们拥有相同的目的地址和目的端
口号，那么不同的报文段将会转交到同一个 UDP 套接字中。


面向连接的多路复用和多路分解指的是 TCP 套接字的分配过程，一个 TCP 套接字由一个四元组来标识，这个四元组包含了
源 IP 地址、源端口号、目的地址和目的端口号。因此，一个 TCP 报文段从网络中到达一台主机上时，该主机使用全部4个
值来将报文段定向到相应的套接字。
### UDP 协议
UDP 是一种无连接的，不可靠的传输层协议。它只提供了传输层需要实现的最低限度的功能，除了复用/分解功能和少量的差
错检测外，它几乎没有对 IP 增加其他的东西。UDP 协议适用于对实时性要求高的应用场景。
特点：


1.  使用 UDP 时，在发送报文段之前，通信双方没有握手的过程，因此 UDP 被称为是无连接的传输层协议。因为没有握手
过程，相对于 TCP 来说，没有建立连接的时延。因为没有连接，所以不需要在端系统中保存连接的状态。 
1.  UDP 提供尽力而为的交付服务，也就是说 UDP 协议不保证数据的可靠交付。 
1.  UDP 没有拥塞控制和流量控制的机制，所以 UDP 报文段的发送速率没有限制。 
1.  因为一个 UDP 套接字只使用目的地址和目的端口来标识，所以 UDP 可以支持一对一、一对多、多对一和多对多的交互
通信。 
1.  UDP 首部小，只有8个字节。 
#### UDP 报文段结构
UDP 报文段由首部和应用数据组成。报文段首部包含四个字段，分别是源端口号、目的端口号、长度和检验和，每个字段的长
度为两个字节。长度字段指的是整个报文段的长度，包含了首部和应用数据的大小。校验和是 UDP 提供的一种差错校验机制。
虽然提供了差错校验的机制，但是 UDP 对于差错的恢复无能为力。


![](https://cavszhouyou-1254093697.cos.ap-chongqing.myqcloud.com/note-16.png#align=left&display=inline&height=192&id=KJ3vG&margin=%5Bobject%20Object%5D&originHeight=192&originWidth=220&status=done&style=none&width=220)
### TCP 协议
TCP 协议是面向连接的，提供可靠数据传输服务的传输层协议。
特点：

1.  TCP 协议是面向连接的，在通信双方进行通信前，需要通过三次握手建立连接。它需要在端系统中维护双方连接的状态信
息。 
1.  TCP 协议通过序号、确认号、定时重传、检验和等机制，来提供可靠的数据传输服务。 
1.  TCP 协议提供的是点对点的服务，即它是在单个发送方和单个接收方之间的连接。 
1.  TCP 协议提供的是全双工的服务，也就是说连接的双方的能够向对方发送和接收数据。 
1.  TCP 提供了拥塞控制机制，在网络拥塞的时候会控制发送数据的速率，有助于减少数据包的丢失和减轻网络中的拥塞程度。 
1.  TCP 提供了流量控制机制，保证了通信双方的发送和接收速率相同。如果接收方可接收的缓存很小时，发送方会降低发送
速率，避免因为缓存填满而造成的数据包的丢失。 



#### TCP 报文段结构
TCP 报文段由首部和数据组成，它的首部一般为 20 个字节。


源端口和目的端口号用于报文段的多路复用和分解。


32比特的序号和32比特的确认号，用与实现可靠数据运输服务。


16比特的接收窗口字段用于实现流量控制，该字段表示接收方愿意接收的字节的数量。


4比特的首部长度字段，该字段指示了以32比特的字为单位的 TCP 首部的长度。


6比特的标志字段，ACK 字段用于指示确认序号的值是有效的，RST、SYN 和 FIN 比特用于连接建立和拆除。设置 PSH 字
段指示接收方应该立即将数据交给上层，URG 字段用来指示报文段里存在紧急的数据。


校验和提供了对数据的差错检测。


![](https://cavszhouyou-1254093697.cos.ap-chongqing.myqcloud.com/note-17.png#align=left&display=inline&height=315&id=uZWV9&margin=%5Bobject%20Object%5D&originHeight=315&originWidth=338&status=done&style=none&width=338)
### 问：那 TCP 和 UDP 有什么区别


UDP协议是**无连接**，尽最大可能交付报文，**没有拥塞控制**，**面向报文（不分割、不合并）**，支持一对一、一对多、多对一、多对多的交互通信，传输效率高；
TCP是面向**连接的**，提供可靠交付，**面向字节流**（从上层传下的数据进行分割，分割成合适运输的数据块）**只能是一对一连接**，传输效率相对较低；


### 问：那什么时候用TCP，什么时候用UDP呢？


不管用TCP和UDP，应用只要看需求，对于TCP更加注重的是可靠性，而不是实时性，如果我发送的数据很重要一点也不能出错，有延迟无所谓的话，那就TCP啊。UDP更加注重是速度快，也就是实时性，对于可靠性要求不那么高，像斗鱼，熊猫这些在线直播网站应该在UDP基础是封装了其他协议，比如视频实时传输协议。而且UDP的支持多播，那就很符合这些直播网站了，有时候看直播视频卡顿，人飘逸那可能就是丢包了，但是你也只能往下看。


### 问：DNS 为什么使用 UDP 协议作为传输层协议？


```
DNS 使用 UDP 协议作为传输层协议的主要原因是为了避免使用 TCP 协议时造成的连接时延。因为为了得到一个域名的 IP 地
址，往往会向多个域名服务器查询，如果使用 TCP 协议，那么每次请求都会存在连接时延，这样使 DNS 服务变得很慢，因为大
多数的地址查询请求，都是浏览器请求页面时发出的，这样会造成网页的等待时间过长。

使用 UDP 协议作为 DNS 协议会有一个问题，由于历史原因，物理链路的最小MTU = 576，所以为了限制报文长度不超过576，
UDP 的报文段的长度被限制在 512 个字节以内，这样一旦 DNS 的查询或者应答报文，超过了 512 字节，那么基于 UDP 的
DNS 协议就会被截断为 512 字节，那么有可能用户得到的 DNS 应答就是不完整的。这里 DNS 报文的长度一旦超过限制，并不
会像 TCP 协议那样被拆分成多个报文段传输，因为 UDP 协议不会维护连接状态，所以我们没有办法确定那几个报文段属于同一
个数据，UDP 只会将多余的数据给截取掉。为了解决这个问题，我们可以使用 TCP 协议去请求报文。

DNS 还存在的一个问题是安全问题，就是我们没有办法确定我们得到的应答，一定是一个安全的应答，因为应答可以被他人伪造，
所以现在有了 DNS over HTTPS 来解决这个问题。
```
### 问：刚才你说 TCP 是可靠的连接，它是怎么实现的


TCP为应用程序提供可靠的通信连接，因为他采用了三次握手协议，三次握手协议指的是在发送数据的准备阶段，服务器端和客户端之间需要进行三次交互。而断开则是四次挥手，为了保障数据不丢失及错误（可靠性），它有报文校验、ACK 应答、超时重传 (发送方)、失序数据重传（接收方）、丢弃重复数据、流量控制（滑动窗口）和拥塞控制等机制。


### 问：具体说一说三次握手和四次挥手机制


第一次握手：客户端发送SYN包到服务器，并进行SYN_SEND状态，等待服务器确认；
第二次握手：服务器收到SYN包并确认，同时自己发送一个SYN+ACK包，此时服务器进入SYN_RECV状态
第三次握手：客户端收到服务器的SYN_ACK包，向服务器发送确认包ACK，此包发送完毕，客户端和服务器进入established状态，完成三次握手
连接建立后，客户端和服务器就开始进行安全可靠的数据传输了。


> **注意：服务器主动处于"LISTEN"状态等待客户端发送第一次握手的SYN包后，进入SYN_SEND状态**
> **第一、二次握手，只发送请求报文（不包含数据）**
> **第三次握手，连接建立，可以携带报文数据**

[

](https://blog.csdn.net/likewind1993/article/details/98382555)
ACK 表示“确认号”有效，TCP规定，连接建立后，所有传送的报文段必须把ACK置1SYN，建立连接时用于同步，（SYN=1,ACK=0）表示是连接请求报文段，若对方同意建立连接，响应报文为（SYN=1,ACK=1）
FIN，用来释放连接，当FIN=1时，表示发送方数据发送完毕，并要求释放连接。
![image.png](https://cdn.nlark.com/yuque/0/2021/png/12745046/1624365696270-4e84e4d7-6988-48b1-b356-9e5001007f61.png#align=left&display=inline&height=350&id=rFgIX&margin=%5Bobject%20Object%5D&name=image.png&originHeight=510&originWidth=618&size=131960&status=done&style=none&width=424)![image.png](https://cdn.nlark.com/yuque/0/2021/png/12745046/1624455890790-9ba9fd14-c6bd-45ef-a451-dd6c2c34f5e2.png#align=left&display=inline&height=364&id=uc60cc222&margin=%5Bobject%20Object%5D&name=image.png&originHeight=499&originWidth=812&size=182561&status=done&style=none&width=593)
（1）第一次挥手：


数据传输完毕，客户端想要释放连接（没有数据需要传输给服务端了），于是向服务端发送一段TCP报文请求释放连接，然后进入终止等待状态一。并且停止在客户端到服务端方向上发送数据，但是客户端仍然能接收从服务端传输过来的数据。FIN=1 表示请求释放连接, u为随机生成的起始报文段序号（FIN=1，seq=u）


（2）第二次挥手：


服务端收到连接释放报文，立即发出确认报文，表示接收到客户端发送的释放连接的请求，并进入关闭等待状态。（ACK=1，seq=v，ack=u+1）


（3）第三次挥手：


服务端自从发出ACK确认报文之后，经过了关闭等待阶段，做好了释放服务器端到客户端方向上的连接准备，再次向客户端发出一段TCP报文表示已经准备好释放连接了（没有数据需要传输给客户端了），然后进入最后确认状态。（FIN=1，ACK=1，seq=w，ack=u+1）


（4）第四次挥手：


客户端收到从服务器端发出的TCP报文，确认了服务器端已做好释放连接的准备，于是再次向服务端发送报文表示接收到服务端准备好释放连接的信号，并进入TIME-WAIT阶段等待2MSL ( 最大报文生存时间) 后再断开连接，服务端收到最终确认报文后立即断开连接，双方断开TCP连接。（ACK=1，seq=u+1，ack=w+1）
![image.png](https://cdn.nlark.com/yuque/0/2021/png/12745046/1624365782007-4522edd4-6619-489e-bf79-7924709d23c0.png#align=left&display=inline&height=392&id=jb265&margin=%5Bobject%20Object%5D&name=image.png&originHeight=661&originWidth=702&size=167056&status=done&style=none&width=416)![image.png](https://cdn.nlark.com/yuque/0/2021/png/12745046/1624539114082-acdeab6e-10e6-426f-91da-e5e0d3820aea.png#align=left&display=inline&height=364&id=TqiuW&margin=%5Bobject%20Object%5D&name=image.png&originHeight=504&originWidth=700&size=57152&status=done&style=none&width=506)
### 
### 问：**为什么“握手”是三次？ 为什么“挥手”却要四次？**


TCP 建立连接时，通过三次握手**能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同**
**步初始化序列号**。序列号能够保证数据包不重复、不丢弃和按序传输。
关闭连接时需要四次挥手，比建立时多一次，是因为被动关闭端或许还有数据没被送出去，不能像握手时一样，第二次握手既是发起握手也是响应握手


### 问：**如果只有两次握手会发生什么？**


两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接
收。
服务端可能收到已失效的连接请求报文段，之后傻傻等待，浪费资源。


“已失效的连接请求报文段”产生在这样一种情况下：
客户端发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达服务端。本来这是一个早已失效的报文段，但服务端收到此失效的连接请求报文段后，就误认为是客户端再次发出的一个新的连接请求。于是就向客户端发出确认报文段，同意建立连接。


假设不采用“三次握手”，那么只要服务端发出确认，新的连接就建立了。由于现在客户端并没有发出建立连接的请求，因此不会理睬服务端的确认，也不会向服务发送数据包，而此时服务端在等待客户端给它发送数据，造成资源浪费。


### 问：为什么客户端和服务端的初始序列号 ISN 是不相同的？


如果一个已经失效的连接被重用了，但是该旧连接的历史报文还残留在网络中，如果序列号相同，那么
就无法分辨出该报文是不是历史报文，如果历史报文被新的连接接收了，则会产生数据错乱。
所以，每次建立连接前重新初始化一个序列号主要是为了通信双方能够根据序号将不属于本连接的报文
段丢弃。
另一方面是为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收。


### 问：TIME_WAIT 和 CLOSE_WAIT 的区别在哪


CLOSE_WAIT 是被动关闭形成的；当对方 close socket 而发送 FIN 报文过来时，回应 ACK 之后进入 CLOSE_WAIT 状态。随后检查是否存在未传输数据，如果没有则发起第三次挥手，发送 FIN 报文给对方，进入 LAST_ACK 状态并等待对方 ACK 报文到来；TIME_WAIT 是主动关闭连接方式形成的；处于 FIN_WAIT_2 状态时，收到对方 FIN 报文后进入 TIME_WAIT 状态；之后再等待两个 MSL(Maximum Segment Lifetime: 报文最大生存时间)


### 问：为什么需要 TIME_WAIT 状态？**为什么客户端在TIME-WAIT阶段要等2MSL?**
> MSL 是 Maximum Segment Lifetime，**报文最大生存时间**，它是任何报文在网络上存在的最长时间，
> 超过这个时间报文将被丢弃。



需要 TIME-WAIT 状态，主要是两个原因：
防止具有相同「四元组」的「旧」数据包被收到；
保证「被动关闭连接」的一方能被正确的关闭，即保证最后的 ACK 能让被动关闭方接收，从而帮
助其正常关闭；


等2MSL的目的是确认服务器端是否收到客户端发出的最终ACK确认报文。
当客户端发出最后的ACK确认报文时，并不能确定服务器端能够收到该段报文。所以客户端在发送完ACK确认报文之后，会设置一个时长为2MSL的计时器。MSL指的是：一段TCP报文在传输过程中的最大生命周期。2MSL即是一个发送和一个回复所需的最大时间。


服务端如果在1MSL内没有收到客户端发出的最终ACK确认报文（说明最终确认报文丢失了），就会再次向客户端发出FIN报文。


如果客户端在2MSL内，再次收到了来自服务器端的FIN报文，说明服务器端由于各种原因没有接收到客户端发出的ACK确认报文。客户端再次向服务器端发出ACK确认报文，计时器重置，重新开始2MSL的计时。


所以，客户端要经历时长为2MSLL的TIME-WAIT阶段；这也是为什么客户端比服务器端晚进入CLOSED阶段的原因。


### 问：如果已经建立了连接，但是客户端突然出现故障了怎么办


TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接
### 问：TCP如何保证可靠性传输

- 重传机制（ARQ 协议）
   - TCP 针对数据包丢失的情况，会用**重传机制**解决
      - **超时重传**
         - 重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方

的 ACK 确认应答报文，就会重发该数据，也就是我们常说的**超时重传**。TCP 会在数据包丢失、确认应答丢失两种情况发生超时重传

      - **快速重传**
         - 快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。
      - **SACK 方法**
         - 还有一种实现重传机制的方式叫： SACK （ Selective Acknowledgment 选择性确认）。这种方式需要在 TCP 头部「选项」字段里加一个 SACK 的东西，它**可以将缓存的地图发送给发送方**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。
- 滑动窗口
   - 我们都知道 TCP 是每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了， 再发送下一个。这个模式就有点像我和你面对面聊天，你一句我一句。但这种方式的缺点是效率比较低的。如果你说完一句话，我在处理其他事情，没有及时回复你，那你不是要干等着我做完其他事情后，我回复你，你才能说下一句话，很显然这不现实。所以，这样的传输方式有一个缺点：数据包的**往返时间越长，通信的效率就越低**。为解决这个问题，TCP 引入了**窗口**这个概念。即使在往返时间较长的情况下，它也不会降低网络通信的效率。那么有了窗口，就可以指定窗口大小，窗口大小就是指**无需等待确认应答，而可以继续发送数据的最大值**。所以，通常窗口的大小是由接收方的窗口大小来决定的。发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。
   -  滑动窗口通俗来讲就是一种流量控制技术。 它本质上是描述接收方的TCP数据报缓冲区大小的数据，发送方根据这个数据来计算自己最多能发送多长的数据，如果发送方收到接收方的窗口大小为0的TCP数据报，那么发送方将停止发送数据，等到接收方发送窗口大小不为0的数据报的到来。
- 流量控制
   - 发送方不能无脑的发数据给接收方，要考虑接收方处理能力。如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。为了解决这种现象发生，**TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。**
- 拥塞控制
   - 前面的流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。**在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大....**所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。于是，就有了**拥塞控制**，控制的目的就是**避免「发送方」的数据填满整个网络。**为了在「发送方」调节所要发送数据的量，定义了一个叫做「**拥塞窗口**」的概念。
### 问：刚才你还有提到拥塞控制，TCP 协议用什么方式去解决拥塞的


**第一方式是慢启动和拥塞避免**
1）慢启动，TCP 发送端会维护一个拥塞窗口（congestionwindow）, 简称为 cwnd。**拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**。TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量，如果一上来就发大量的数据，这不是给网络添堵吗？慢启动的算法记住一个规则就行：**当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。**
2）拥塞避免，那慢启动涨到什么时候是个头呢？有一个叫慢启动门限 ssthresh （slow start threshold）状态变量。当 cwnd < ssthresh 时，使用慢启动算法。当 cwnd >= ssthresh 时，就会使用「拥塞避免算法」。进入拥塞避免算法后，它的规则是：**每当收到一个 ACK 时，cwnd 增加 1/cwnd。**如果遇到网络拥塞，拥塞窗口阀值 ssthresh 减半，cwnd 设置为 1，重新进入慢启动阶段


![image.png](https://cdn.nlark.com/yuque/0/2021/png/12745046/1624454855940-f995abd3-9510-4dc1-94e8-3d9146eb8ee2.png#align=left&display=inline&height=480&id=ueead0942&margin=%5Bobject%20Object%5D&name=image.png&originHeight=480&originWidth=1001&size=127925&status=done&style=none&width=1001)
**第二方式快重传和快恢复**
1）快重传是当接收方收到了一个失序的报文，则立马报告给发送方，赶紧重传；假如接收方 M1 收到了，M2 没有收到，之后的 M3、M4、M5 又发送了，此时接收方一共连续给发送方反馈了 3 个 M1 确认报文。那么快重传规定，发送方只要连续收到 3 个重复确认，立即重传对方发来的 M2（重复确认报文的后一个报文）
2）快恢复，当发送方连续收到三个重复确认，ssthresh 减半；由于发送方可能认为网络现在没有拥塞，因此与慢启动不同，把 cwnd 值设置为 ssthresh 减半之后的值，然后执行拥塞避免算法，cwnd 线性增大
 ![image.png](https://cdn.nlark.com/yuque/0/2021/png/12745046/1624454931341-50286837-09c9-455c-906b-8f83e0954d4d.png#align=left&display=inline&height=457&id=u72c88496&margin=%5Bobject%20Object%5D&name=image.png&originHeight=457&originWidth=1056&size=155807&status=done&style=none&width=1056)
### 
### 问：知道滑动窗口不，客户端和服务端控制滑动窗口的过程是怎样的


接收端将自己可以接收的缓冲区大小放入 TCP 首部中的 “窗口大小” 字段，通过 ACK 报文来通知发送端，滑动窗口是接收端用来控制发送端发送数据的大小，从而达到流量控制
其实发送方的窗口上限，是取值拥塞窗口和滑动窗口两者的最小值


### 问：你知道滑动窗口和拥塞窗口有什么区别不


相同点都是控制丢包现象，实现机制都是让发送方发得慢一点
不同点在于控制的对象不同
1）流量控制的对象是接收方，怕发送方发的太快，使得接收方来不及处理
2）拥塞控制的对象是网络，怕发送方发的太快，造成网络拥塞，使得网络来不及处理


### 问：TCP 的粘包和拆包问题，你怎么看


程序需要发送的数据大小和 TCP 报文段能发送 MSS（Maximum Segment Size，最大报文长度）是不一样的，大于 MSS 时，而需要把程序数据拆分为多个 TCP 报文段，称之为拆包；小于时，则会考虑合并多个程序数据为一个 TCP 报文段，则是粘包；其中 MSS = TCP 报文段长度 - TCP 首部长度，在 IP 协议层或者链路层、物理层，都存在拆包、粘包现象


### 问：那解决粘包和拆包的方法都有哪些


1）在数据尾部增加特殊字符进行分割
2）将数据定为固定大小
3）将数据分为两部分，一部分是头部，一部分是内容体；其中头部结构大小固定，且有一个字段声明内容体的大小
### 问：SYN Flood 了解吗/什么是 SYN 攻击？如何避免 SYN 攻击？
SYN Flood 伪造 SYN 报文向服务器发起连接，服务器在收到报文后用 SYN_ACK 应答，此应答发出去后，不会收到 ACK 报文，造成一个半连接
若攻击者发送大量这样的报文，会在被攻击主机上出现大量的半连接，耗尽其资源，使正常的用户无法访问，直到半连接超时
解决方案
其中一种解决方式是通过修改 Linux 内核参数，控制队列大小和当队列满时应做什么处理。
另一种解决方式是当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不进入「 SYN 队列」计算出一个 cookie 值，再以 SYN + ACK 中的「序列号」返回客户端，服务端接收到客户端的应答报文时，服务器会检查这个 ACK 包的合法性。如果合法，直接放入到「 Accept 队列，最后应用通过调用 accpet() socket 接口，从「 Accept 队列」取出的连接。
[https://blog.csdn.net/CC_Together/article/details/105575364](https://blog.csdn.net/CC_Together/article/details/105575364)[https://www.cnblogs.com/xmanblue/p/14191429.html](https://www.cnblogs.com/xmanblue/p/14191429.html)
[https://blog.csdn.net/likewind1993/article/details/98382555](https://blog.csdn.net/likewind1993/article/details/98382555)
## 4. 网络层 IP

- 分类地址
- 无分类地址 CIDR 子网掩码 
- 划分子网



### IPv6（略）
网际协议第 6 版（英语：Internet Protocol version 6，缩写：IPv6）是网际协议的最新版本，用作互联网的协议。用它来取代 IPv4 主要是为了解决 IPv4 地址枯竭问题，同时它也在其他方面对于 IPv4 有许多改进。
IPv6 目的：

- 更大的地址空间：128 位长度
- 更好的地址空间管理
- 消除 NAT 等寻址技术
- 更简易的 IP 配置管理
- 优秀的选路设计
- 更好的多播支持
- 安全性
- 移动性



Pv6 二进位制下为 128 位长度，以 16 位为一组，每组以冒号 `:` 隔开，可以分为 8 组，每组以 4 位十六进制方式表示。例如：`2001:0db8:86a3:08d3:1319:8a2e:0370:7344` 是一个合法的 IPv6 地址。
类似于 IPv4 的点分十进制，同样也存在点分十六进制的写法，将 8 组 4 位十六进制地址的冒号去除后，每位以点号 `.` 分组，例如：`2001:0db8:85a3:08d3:1319:8a2e:0370:7344` 则记为 `2.0.0.1.0.d.b.8.8.5.a.3.0.8.d.3.1.3.1.9.8.a.2.e.0.3.7.0.7.3.4.4`，其倒序写法用于 `ip6.arpa` 子域名记录 IPv6 地址与域名的映射。


IPv4 位址可以很容易的转化为 IPv6 格式。举例来说，如果 IPv4 的一个地址为 `135.75.43.52`（十六进制为 `0x874B2B34`），它可以被转化为 `0000:0000:0000:0000:0000:FFFF:874B:2B34` 或者 `::FFFF:874B:2B34`。同时，还可以使用混合符号（IPv4-compatible address），则地址可以为 `::ffff:135.75.43.52`。


### NAT 地址转换（略）
网络地址转换（Network Address Translation，缩写：NAT；又称网络掩蔽、IP 掩蔽）在计算机网络中是一种在 IP 数据包通过路由器或防火墙时重写来源 IP 地址或目的 IP 地址的技术。
这种技术被普遍使用在有多台主机但只通过一个公有 IP 地址访问互联网的私有网络中。它是一个方便且得到了广泛应用的技术。当然，NAT 也让主机之间的通信变得复杂，导致了通信效率的降低。
## 5. 链路层 ARP、MAC

- mac地址
- arp地址解析协议




---

## 参考链接
[https://tsejx.github.io/javascript-guidebook/computer-networks](https://tsejx.github.io/javascript-guidebook/computer-networks)
[https://zoumiaojiang.com/article/common-web-security/](https://zoumiaojiang.com/article/common-web-security/)
